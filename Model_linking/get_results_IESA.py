import pandas as pd
from pathlib import Path

import config_model_linking as cfg
from conversion_factors import conversion_factor_IESA_to_cluster

def get_results_IESA_dict(results_file_path):
    """
    Extracts data from multiple sheets of an Excel file generated by IESA-Opt,
    using specified filters and headers for different intervals and sheets.

    Args:
        results_file_path (str or Path): Path to Excel file

    Returns:
        dict: Nested dict with keys 'results_<interval>_<sheet>' containing lists of filtered entries
    """
    print("Start extracting data from IESA-Opt")

    # Validate input lengths
    if len({len(cfg.list_sheets), len(cfg.nrows), len(cfg.headers), len(cfg.filters)}) != 1:
        raise ValueError("All input lists (sheets, nrows, headers, filters) must have the same length.")

    results_dict = {}

    # Iterate over sheets and associated filter definitions
    for sheet_name, num_rows, header, sheet_filters in zip(cfg.list_sheets, cfg.nrows, cfg.headers, cfg.filters):
        df = pd.read_excel(results_file_path, sheet_name=sheet_name, nrows=num_rows, header=0)

        # Validate header presence once
        if isinstance(header, str):
            if header not in df.columns:
                raise ValueError(f"Header '{header}' not found in sheet '{sheet_name}'.")
        elif isinstance(header, tuple):
            missing = [h for h in header if h not in df.columns]
            if missing:
                raise ValueError(f"Headers {missing} not found in sheet '{sheet_name}'.")

        # Process each interval
        for interval in cfg.intervals:
            key = f"results_{interval}_{sheet_name}"
            results_dict.setdefault(key, [])

            # Filter rows based on provided filters
            for filter_value in sheet_filters:
                filter_entry = {}

                if isinstance(header, str):
                    condition = df[header] == filter_value
                    filter_entry[header] = filter_value
                elif isinstance(header, tuple) and isinstance(filter_value, tuple):
                    if len(header) != len(filter_value):
                        raise ValueError(f"Mismatch between header and filter tuple lengths in sheet '{sheet_name}'.")
                    condition = pd.Series(True, index=df.index)
                    for h, f in zip(header, filter_value):
                        condition &= df[h] == f
                        filter_entry[h] = f
                else:
                    raise ValueError(f"Header/filter mismatch in sheet '{sheet_name}': {header}, {filter_value}")

                matched_rows = df[condition]

                if matched_rows.empty:
                    raise ValueError(
                        f"No match found for filter {filter_entry} in sheet '{sheet_name}' for year '{interval}'."
                    )

                try:
                    extracted_value = float(matched_rows[interval].values[0])
                except KeyError:
                    raise ValueError(
                        f"Year column '{interval}' not found in sheet '{sheet_name}'.\n"
                        f"Available columns: {list(df.columns)}"
                    )

                filter_entry["value"] = extracted_value
                results_dict[key].append(filter_entry)

    print("The raw results dictionary from IESA-Opt is created")
    return results_dict


def convert_IESA_to_cluster_dict(results_IESA_dict, results_path_IESA):
    cluster_results = {}

    for interval in cfg.intervals:
        interval_data = {}

        # --- Linking energy prices ---
        if cfg.linking_energy_prices:
            sheet_key = f"results_{interval}_EnergyCosts"

            for entry in results_IESA_dict.get(sheet_key, []):
                activity = entry.get("Activity")
                value = entry.get("value")
                conv = conversion_factor_IESA_to_cluster('EnergyCosts', activity)
                carrier = cfg.cluster_carrier_names[activity]
                check_prod = check_carrier_prod_IESA(results_path_IESA, interval, activity)
                if check_prod:
                    interval_data[carrier] = conv * value
                else:
                    interval_data[carrier] = None

            # Special case: Bio Methane
            bio_cost = calculate_avg_bio_methane_cost(results_path_IESA, interval)
            conv_bio = conversion_factor_IESA_to_cluster('EnergyCosts', 'methane_bio')
            interval_data['methane_bio'] = conv_bio * bio_cost if bio_cost is not None else None

        # # --- Linking MPW availability ---
        if cfg.linking_MPW:
            sheet_key = f"results_{interval}_SupplyDemand"
            total_mpw_supply = 0.0

            for entry in results_IESA_dict.get(sheet_key, []):
                if entry.get("Activity") == "Mixed Plastic Waste" and entry.get("Type") == "supply":
                    tech_id = entry.get("Tech_ID")
                    value = entry.get("value")

                    if value is None:
                        print(f"⚠️ No value found for Tech_ID '{tech_id}' in interval {interval}")
                        continue

                    try:
                        factor = conversion_factor_IESA_to_cluster("SupplyDemand", tech_id)
                        total_mpw_supply += factor * value
                    except Exception as e:
                        print(f"⚠️ Skipping {tech_id} due to error: {e}")

            # Store the MPW import limit in cluster model input and PyPSA structure
            interval_data['Import limit MPW'] = total_mpw_supply

        cluster_results[interval] = interval_data

    return {cfg.location: cluster_results}


def check_carrier_prod_IESA(file_path, interval, carrier):
    """
    Check if there is any positive supply for a given carrier at a given interval.

    Args:
        file_path (str): Path to the Excel file.
        interval (str or int): Column name representing the time interval.
        carrier (str): Carrier name to check.

    Returns:
        bool: True if there is positive supply, False otherwise.
    """
    try:
        df_sd = pd.read_excel(file_path, sheet_name="SupplyDemand")
    except Exception as e:
        raise ValueError(f"❌ Failed to load Excel sheet 'SupplyDemand': {e}")

    # Filter rows where the activity matches the carrier and type is 'supply'
    mask = (df_sd["Activity"] == carrier) & (df_sd["Type"] == "supply")
    relevant_rows = df_sd.loc[mask]

    try:
        # Safely extract values for the given interval
        values = relevant_rows[interval].values
        total_output = pd.to_numeric(values, errors='coerce').sum()
        return total_output > 0
    except KeyError:
        raise ValueError(f"❌ Interval '{interval}' not found in the Excel file.")
    except Exception as e:
        raise ValueError(f"❌ Failed to compute supply value: {e}")


def calculate_avg_bio_methane_cost(file_path, year):
    """
    Calculates the weighted average cost of bio-methane production based on LCOE components
    and technology outputs for a given year. Provides a summary of found and missing data.

    Args:
        file_path (str or Path): Path to the Excel file containing IESA output data
        year (str): The target year to extract values for

    Returns:
        float or None: The weighted average cost, or None if no output is found
    """

    technologies = ["Gas04_01", "Gas04_02", "Gas04_03", "Gas04_04"]
    components = ["CAPEX", "FOM", "VOC", "Fuels"]

    try:
        df_lcoe = pd.read_excel(file_path, sheet_name="LCOEs")
        df_sd = pd.read_excel(file_path, sheet_name="SupplyDemand")
    except Exception as e:
        raise ValueError(f"❌ Failed to load Excel sheets: {e}")

    # === Extract LCOE values ===
    costs = []
    found_costs = {}  # {tech: [found components]}
    for tech in technologies:
        total_cost = 0
        found_components = []
        for comp in components:
            mask = (
                (df_lcoe["Tech_ID"] == tech) &
                (df_lcoe["Type1"] == "Real") &
                (df_lcoe["Type2"] == comp)
            )
            row = df_lcoe[mask]
            try:
                val = float(row[year].values[0])
                total_cost += val
                found_components.append(comp)
            except (IndexError, KeyError, ValueError):
                pass  # missing component is allowed
        if found_components:
            found_costs[tech] = found_components
        costs.append((tech, total_cost))

    # === Extract output values ===
    outputs = []
    found_outputs = []
    for tech in technologies:
        mask = (
            (df_sd["Type"] == "supply") &
            (df_sd["Tech_ID"] == tech)
        )
        row = df_sd[mask]
        try:
            output = float(row[year].values[0])
            if output > 0:
                found_outputs.append(tech)
        except (IndexError, KeyError, ValueError):
            output = 0
        outputs.append((tech, output))

    # === Summary: what was found ===
    print("\n📦 Bio-methane output summary:")
    if found_outputs:
        print(f"Found outputs for: {', '.join(found_outputs)} in {year}")
    else:
        print(f"⚠️ No outputs found for any bio-methane technologies in {year}.")

    # === Weighted average cost calculation ===
    weighted_sum = sum(c * o for (t1, c), (t2, o) in zip(costs, outputs) if o)
    total_output = sum(o for _, o in outputs if o)

    avg_cost = weighted_sum / total_output if total_output > 0 else None

    return avg_cost